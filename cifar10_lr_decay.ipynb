{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# import package\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from pyimagesearch.nn.conv import MiniVGGNet\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    # init the base learning rate, drop factor and epoch to drop\n",
    "    initAlpha = 0.01\n",
    "    factor = 0.25\n",
    "    dropEvery = 5\n",
    "\n",
    "    # compute learning rate for the current epoch\n",
    "    alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery))\n",
    "\n",
    "    return float(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'output' : '/output/lr_decay_f0.25_plot.png'\n",
    "}\n",
    "\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, tainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype('float') / 255.0\n",
    "testX = testX.astype('float') / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# initialzie the label names\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the set of callbacks to be passed to the modesl during training\n",
    "callbacks = [LearningRateScheduler(step_decay)]\n",
    "\n",
    "# init the optimizer and model\n",
    "opt = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# train the network\n",
    "H = model.fit(trainX, trainY, validation_data(testX, testY),\n",
    "batch_size=64, epochs=40, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute the network\n",
    "print(\"[info] evaluating the network..\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 40), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  }
 ]
}